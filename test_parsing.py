import requests
from bs4 import BeautifulSoup
import time

def test_lex_uz():
    """–¢–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ lex.uz"""
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ lex.uz...")
    
    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É
        search_url = "https://lex.uz/ru/search?q=—É–≥–æ–ª–æ–≤–Ω—ã–π+–∫–æ–¥–µ–∫—Å"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        print(f"üì° –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞: {search_url}")
        response = requests.get(search_url, headers=headers, timeout=30)
        response.raise_for_status()
        
        print(f"‚úÖ –°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status_code}")
        print(f"üìÑ –†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞: {len(response.content)} –±–∞–π—Ç")
        
        # –ü–∞—Ä—Å–∏–º HTML
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        print("\nüîç –ü–æ–∏—Å–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ:")
        
        # –ü–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        titles = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
        print(f"   –ó–∞–≥–æ–ª–æ–≤–∫–∏ (h1-h6): {len(titles)}")
        
        # –ü–æ–∏—Å–∫ —Å—Å—ã–ª–æ–∫
        links = soup.find_all('a')
        print(f"   –°—Å—ã–ª–∫–∏: {len(links)}")
        
        # –ü–æ–∏—Å–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º
        search_results = soup.find_all('div', class_='search-result')
        print(f"   div.search-result: {len(search_results)}")
        
        results = soup.find_all('div', class_='result')
        print(f"   div.result: {len(results)}")
        
        # –ü–æ–∏—Å–∫ –ø–æ ID
        content_div = soup.find('div', id='content')
        print(f"   div#content: {'–ù–∞–π–¥–µ–Ω' if content_div else '–ù–µ –Ω–∞–π–¥–µ–Ω'}")
        
        main_div = soup.find('div', id='main')
        print(f"   div#main: {'–ù–∞–π–¥–µ–Ω' if main_div else '–ù–µ –Ω–∞–π–¥–µ–Ω'}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Å—ã–ª–æ–∫
        print(f"\nüîó –ü–µ—Ä–≤—ã–µ 5 —Å—Å—ã–ª–æ–∫:")
        for i, link in enumerate(links[:5]):
            href = link.get('href', '')
            text = link.get_text(strip=True)[:50]
            print(f"   {i+1}. {text} -> {href}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        print(f"\nüìã –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã:")
        for tag in soup.find_all(['div', 'section', 'article'])[:10]:
            class_attr = tag.get('class', [])
            id_attr = tag.get('id', '')
            if class_attr or id_attr:
                print(f"   <{tag.name} class='{class_attr}' id='{id_attr}'>")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ lex.uz: {e}")
        return False

def test_norma_uz():
    """–¢–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ norma.uz"""
    print("\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ norma.uz...")
    
    try:
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
        search_url = "https://norma.uz/search?q=—É–≥–æ–ª–æ–≤–Ω—ã–π+–∫–æ–¥–µ–∫—Å"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        print(f"üì° –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞: {search_url}")
        response = requests.get(search_url, headers=headers, timeout=30)
        response.raise_for_status()
        
        print(f"‚úÖ –°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status_code}")
        print(f"üìÑ –†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞: {len(response.content)} –±–∞–π—Ç")
        
        # –ü–∞—Ä—Å–∏–º HTML
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        print("\nüîç –ü–æ–∏—Å–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ:")
        
        # –ü–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        titles = soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
        print(f"   –ó–∞–≥–æ–ª–æ–≤–∫–∏ (h1-h6): {len(titles)}")
        
        # –ü–æ–∏—Å–∫ —Å—Å—ã–ª–æ–∫
        links = soup.find_all('a')
        print(f"   –°—Å—ã–ª–∫–∏: {len(links)}")
        
        # –ü–æ–∏—Å–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º
        search_results = soup.find_all('div', class_='search-result')
        print(f"   div.search-result: {len(search_results)}")
        
        results = soup.find_all('div', class_='result')
        print(f"   div.result: {len(results)}")
        
        # –ü–æ–∏—Å–∫ –ø–æ ID
        content_div = soup.find('div', id='content')
        print(f"   div#content: {'–ù–∞–π–¥–µ–Ω' if content_div else '–ù–µ –Ω–∞–π–¥–µ–Ω'}")
        
        main_div = soup.find('div', id='main')
        print(f"   div#main: {'–ù–∞–π–¥–µ–Ω' if main_div else '–ù–µ –Ω–∞–π–¥–µ–Ω'}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Å—ã–ª–æ–∫
        print(f"\nüîó –ü–µ—Ä–≤—ã–µ 5 —Å—Å—ã–ª–æ–∫:")
        for i, link in enumerate(links[:5]):
            href = link.get('href', '')
            text = link.get_text(strip=True)[:50]
            print(f"   {i+1}. {text} -> {href}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ norma.uz: {e}")
        return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–∞–π—Ç–æ–≤")
    print("=" * 50)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º lex.uz
    lex_success = test_lex_uz()
    
    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    time.sleep(2)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º norma.uz
    norma_success = test_norma_uz()
    
    print("\n" + "=" * 50)
    print("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:")
    print(f"   lex.uz: {'‚úÖ –£—Å–ø–µ—à–Ω–æ' if lex_success else '‚ùå –û—à–∏–±–∫–∞'}")
    print(f"   norma.uz: {'‚úÖ –£—Å–ø–µ—à–Ω–æ' if norma_success else '‚ùå –û—à–∏–±–∫–∞'}")
    
    if lex_success and norma_success:
        print("\nüéØ –û–±–∞ —Å–∞–π—Ç–∞ –¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞!")
    else:
        print("\n‚ö†Ô∏è –ï—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–∞—Ä—Å–∏–Ω–≥–æ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–∞–π—Ç–æ–≤")

if __name__ == "__main__":
    main()
